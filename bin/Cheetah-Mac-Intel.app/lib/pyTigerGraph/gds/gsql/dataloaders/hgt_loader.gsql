CREATE QUERY hgt_loader_{QUERYSUFFIX}(
    SET<VERTEX> input_vertices,
    INT batch_size,
    INT num_batches=1, 
    INT num_hops=2, 
    BOOL shuffle=FALSE,
    STRING filter_by,
    SET<STRING> v_types,
    SET<STRING> e_types,
    SET<STRING> seed_types,
    STRING delimiter,
    STRING kafka_address="",
    STRING kafka_topic,
    INT kafka_topic_partitions=1,
    STRING kafka_max_size="104857600",
    INT kafka_timeout=300000,
    STRING security_protocol="",
    STRING sasl_mechanism="",
    STRING sasl_username="",
    STRING sasl_password="",
    STRING ssl_ca_location="",
    STRING ssl_certificate_location="",
    STRING ssl_key_location="",
    STRING ssl_key_password="",
    STRING ssl_endpoint_identification_algorithm="",
    STRING sasl_kerberos_service_name="",
    STRING sasl_kerberos_keytab="",
    STRING sasl_kerberos_principal="",
    INT num_heap_inserts = 10
) SYNTAX V1 { 
    /*
    This query generates the neighborhood subgraphs of given seed vertices (i.e., `input_vertices`).
    If seed vertices are not given, then it will divide all vertices into `num_batches`, and use each 
    batch as seeds.

    Parameters :
      input_vertices : Seed vertices to gather neighborhood subgraphs.
      num_batches    : Number of batches to divide all vertices into.
      num_hops       : Number of hops to traverse to get neighbors.
      shuffle        : Whether to shuffle vertices before collecting data.
      filter_by      : A Boolean attribute to determine which vertices are eligible as seeds.
                       Only effective when `input_vertices` is NULL.
      v_types        : Vertex types to be included.
      e_types        : Edge types to be included.
      seed_types     : Vertex types to be included as seeds.
      kafka_address  : Address of the Kafka cluster to send data to.
      kafka_topic    : The Kafka topic to send data to.
      security_protocol : Security prototol for Kafka.
      sasl_mechanism : Authentication mechanism for Kafka.
      sasl_username  : SASL username for Kafka. 
      sasl_password  : SASL password for Kafka. 
      ssl_ca_location: Path to CA certificate for verifying the Kafka broker key.
    */
    TYPEDEF TUPLE<INT tmp_id, VERTEX v> ID_Tuple;
    INT num_vertices;
    INT kafka_errcode;
    SumAccum<INT> @tmp_id;
    SumAccum<STRING> @@kafka_error;
    UINT producer;
    INT batch_s;
    OrAccum @prev_sampled;

    # Initialize Kafka producer
    IF kafka_address != "" THEN
        producer = init_kafka_producer(
            kafka_address, kafka_max_size, security_protocol, 
            sasl_mechanism, sasl_username, sasl_password, ssl_ca_location,
            ssl_certificate_location, ssl_key_location, ssl_key_password,
            ssl_endpoint_identification_algorithm, sasl_kerberos_service_name,
            sasl_kerberos_keytab, sasl_kerberos_principal);
    END;

    # Shuffle vertex ID if needed
    IF input_vertices.size()==0 THEN
        start = {seed_types};
        IF filter_by IS NOT NULL THEN
            start = SELECT s FROM start:s WHERE s.getAttr(filter_by, "BOOL");
        END;
        IF shuffle THEN
            num_vertices = start.size();
            res = SELECT s 
                FROM start:s
                POST-ACCUM s.@tmp_id = floor(rand()*num_vertices);
        ELSE
            res = SELECT s 
                FROM start:s
                POST-ACCUM s.@tmp_id = getvid(s);
        END;
    END;
    IF batch_size IS NULL THEN
      batch_s = ceil(res.size()/num_batches);
    ELSE  
      batch_s = batch_size;
    END;

    # Generate subgraphs
    FOREACH batch_id IN RANGE[0, num_batches-1] DO
        SumAccum<STRING> @@v_batch;
        SumAccum<STRING> @@e_batch;
        SetAccum<VERTEX> @@printed_vertices;
        SetAccum<EDGE> @@printed_edges;
        SetAccum<VERTEX> @@seeds;
        # Get seeds
        IF input_vertices.size()==0 THEN
            start = {seed_types};
            HeapAccum<ID_Tuple> (1, tmp_id ASC) @@batch_heap;
            @@batch_heap.resize(batch_s);
            IF filter_by IS NOT NULL THEN
                FOREACH iter IN RANGE[0,num_heap_inserts-1] DO 
                  _verts = SELECT s FROM start:s
                         WHERE s.@tmp_id % num_heap_inserts == iter AND NOT s.@prev_sampled AND s.getAttr(filter_by, "BOOL")
                         POST-ACCUM @@batch_heap += ID_Tuple(s.@tmp_id, s);
                END;
                FOREACH elem IN @@batch_heap DO
                  @@seeds += elem.v;
                END;
                seeds = {@@seeds};
                seeds = SELECT s 
                        FROM seeds:s 
                        POST-ACCUM 
                            s.@prev_sampled += TRUE,
                            {SEEDVERTEXATTRS},
                            @@printed_vertices += s;
            ELSE
                FOREACH iter IN RANGE[0,num_heap_inserts-1] DO 
                  _verts = SELECT s FROM start:s
                           WHERE s.@tmp_id % num_heap_inserts == iter AND NOT s.@prev_sampled
                           POST-ACCUM @@batch_heap += ID_Tuple(s.@tmp_id, s);
                END;
                FOREACH elem IN @@batch_heap DO
                  @@seeds += elem.v;
                END;
                seeds = {@@seeds};
                seeds = SELECT s 
                        FROM start:s
                        POST-ACCUM
                            s.@prev_sampled += TRUE,
                            {SEEDVERTEXATTRS},
                            @@printed_vertices += s;
            END;
        ELSE
            start = input_vertices;
            seeds = SELECT s 
                    FROM start:s 
                    POST-ACCUM
                        @@printed_vertices += s,
                        {SEEDVERTEXATTRS};
        END;
        # Get neighbors of seeeds
        FOREACH i IN RANGE[1, num_hops] DO
            {SELECTNEIGHBORS}
            attr = SELECT s
                FROM seeds:s 
                POST-ACCUM 
                    IF NOT @@printed_vertices.contains(s) THEN
                        @@printed_vertices += s,
                        {OTHERVERTEXATTRS}
                    END;
        END;
        IF kafka_address != "" THEN
            # Write to kafka
            kafka_errcode = write_to_kafka(producer, kafka_topic, batch_id%kafka_topic_partitions, "vertex_batch_" + stringify(batch_id), @@v_batch);
            IF kafka_errcode!=0 THEN 
                @@kafka_error += ("Error sending vertex batch " + stringify(batch_id) + ": "+ stringify(kafka_errcode) + "\n");
            END;
            kafka_errcode = write_to_kafka(producer, kafka_topic, batch_id%kafka_topic_partitions, "edge_batch_" + stringify(batch_id), @@e_batch);
            IF kafka_errcode!=0 THEN 
                @@kafka_error += ("Error sending edge batch " + stringify(batch_id) + ": "+ stringify(kafka_errcode) + "\n");
            END;
        ELSE
            # Add to response
            IF input_vertices.size()==0 THEN
                PRINT @@v_batch AS vertex_batch, @@e_batch AS edge_batch;  
            ELSE
                MapAccum<UINT, VERTEX> @@id_map;
                source = @@printed_vertices;
                res = 
                    SELECT s 
                    FROM source:s
                    POST-ACCUM @@id_map += (getvid(s) -> s);
                PRINT @@v_batch AS vertex_batch, @@e_batch AS edge_batch, @@id_map AS pids; 
            END;
        END;                          
    END;
    IF kafka_address != "" THEN
        kafka_errcode = close_kafka_producer(producer, kafka_timeout);
        IF kafka_errcode!=0 THEN 
            @@kafka_error += ("Error shutting down Kafka producer: " + stringify(kafka_errcode) + "\n");
        END;
        PRINT @@kafka_error as kafkaError;
    END;
}